{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Batch Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "- **Answer: 3.3.2**\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/06 22:39:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: \n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "We will use this dataset for all the remaining questions.</br>\n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.</br>\n",
    "\n",
    "\n",
    "- 2MB\n",
    "- **Answer: 24MB**\n",
    "- 100MB\n",
    "- 250MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schema\n",
    "schema = types.StructType([\n",
    "    types.StructField(\"dispatching_base_num\", types.StringType(), True),\n",
    "    types.StructField(\"pickup_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"dropoff_datetime\", types.TimestampType(), True),\n",
    "    types.StructField(\"PULocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"DOLocationID\", types.IntegerType(), True),\n",
    "    types.StructField(\"SR_Flag\", types.StringType(), True),\n",
    "    types.StructField(\"Affiliated_base_number\", types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read with spark using schema\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"fhvhv_tripdata_2021-06.csv.gz\")\n",
    "\n",
    "# Repartition to 12 partitions and save to parquet\n",
    "df.repartition(12) \\\n",
    "    .write.parquet(\"data/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 591360\n",
      "-rw-r--r--@ 1 koda  staff     0B Mar  6 22:40 _SUCCESS\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00000-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00001-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00002-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00003-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00004-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00005-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00006-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00007-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00008-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00009-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00010-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n",
      "-rw-r--r--@ 1 koda  staff    24M Mar  6 22:40 part-00011-ddb5cb5e-1906-4d7d-9cc0-bdac130506a6-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15?</br></br>\n",
    "Consider only trips that started on June 15.</br>\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- **Answer: 452,470**\n",
    "- 50,982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('fhvhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM\n",
    "    fhvhv_data\n",
    "WHERE\n",
    "    pickup_datetime >= '2021-06-15 00:00:00' AND\n",
    "    pickup_datetime <= '2021-06-15 23:59:59'\n",
    "\"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>\n",
    "\n",
    "- **Answer: 66.87 Hours**\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropoff_datetime', TimestampType(), True), StructField('PULocationID', IntegerType(), True), StructField('DOLocationID', IntegerType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     trip_duration|\n",
      "+------------------+\n",
      "|  66.8788888888889|\n",
      "|25.549722222222222|\n",
      "|19.980833333333333|\n",
      "|18.197222222222223|\n",
      "|16.466944444444444|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    (unix_timestamp(dropoff_datetime)-unix_timestamp(pickup_datetime)) / 3600 as trip_duration\n",
    "FROM\n",
    "    fhvhv_data\n",
    "ORDER BY\n",
    "    trip_duration DESC\n",
    "LIMIT 5\n",
    "\"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    " Sparkâ€™s User Interface which shows application's dashboard runs on which local port?</br>\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- **Answer: 4040**\n",
    "- 8080"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)</br>\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- **Answer: Crown Heights North**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read with spark\n",
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"taxi_zone_lookup.csv\")\n",
    "\n",
    "df_zones.createOrReplaceTempView('zones_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                Zone| count|\n",
      "+--------------------+------+\n",
      "| Crown Heights North|231279|\n",
      "|        East Village|221244|\n",
      "|         JFK Airport|188867|\n",
      "|      Bushwick South|187929|\n",
      "|       East New York|186780|\n",
      "|TriBeCa/Civic Center|164344|\n",
      "|   LaGuardia Airport|161596|\n",
      "|            Union Sq|158937|\n",
      "|        West Village|154698|\n",
      "|             Astoria|152493|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    z.Zone, Count(*) as count\n",
    "FROM\n",
    "    fhvhv_data f,\n",
    "    zones_data z\n",
    "WHERE\n",
    "    f.PULocationID = z.LocationID\n",
    "GROUP BY\n",
    "    z.Zone\n",
    "ORDER BY\n",
    "    count DESC\n",
    "LIMIT 10\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dez",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0a0b9b2023ffc22575a349ebd5d0d7d9905c9b9c91aa4d34ef34ea7e05ab3bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
